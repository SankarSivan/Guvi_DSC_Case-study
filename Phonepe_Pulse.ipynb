{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SankarSivan/Guvi_DSC_Case-study/blob/main/Phonepe_Pulse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXj8aLm53hoa",
        "outputId": "3adbf217-3abb-4ca3-8a0d-306729e68dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pulse'...\n",
            "remote: Enumerating objects: 17904, done.\u001b[K\n",
            "remote: Counting objects: 100% (2702/2702), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2153/2153), done.\u001b[K\n",
            "remote: Total 17904 (delta 842), reused 2301 (delta 507), pack-reused 15202 (from 1)\u001b[K\n",
            "Receiving objects: 100% (17904/17904), 26.21 MiB | 17.13 MiB/s, done.\n",
            "Resolving deltas: 100% (8584/8584), done.\n",
            "Updating files: 100% (9029/9029), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PhonePe/pulse.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "tTzN1O8Z5q1c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "ufIbS1XmtOHE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Extraction"
      ],
      "metadata": {
        "id": "7BfIjRrseA1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Aggregated Transaction**\n",
        "\n"
      ],
      "metadata": {
        "id": "MJVaMJIxgti4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = \"/content/pulse/data/aggregated/transaction/country/india/state\"\n",
        "Aggr_state_list = os.listdir(path)\n",
        "# print(Aggr_state_list)\n",
        "\n",
        "# Extract the Aggr_data\n",
        "\n",
        "clm = {'state':[], 'year':[], 'quater':[], 'transaction_type':[], 'transaction_count':[], 'transaction_amount':[]}\n",
        "\n",
        "# pull data\n",
        "for i in Aggr_state_list:\n",
        "  p_i = path + '/' + i + '/'\n",
        "  Aggr_yr = os.listdir(p_i)\n",
        "\n",
        "  #print(Aggr_yr)\n",
        "  for j in Aggr_yr:\n",
        "    p_j = p_i + j + '/'\n",
        "    Aggr_qutr = os.listdir(p_j)\n",
        "    #print(Aggr_qutr)\n",
        "\n",
        "    for k in Aggr_qutr:\n",
        "      p_k = p_j + k\n",
        "      Data = open(p_k, 'r')\n",
        "      D = json.load(Data)\n",
        "\n",
        "      for z in D['data']['transactionData']:\n",
        "        Name = z['name']\n",
        "        Count = z['paymentInstruments'][0]['count']\n",
        "        Amount = z['paymentInstruments'][0]['amount']\n",
        "        clm['transaction_type'].append(Name)\n",
        "        clm['transaction_count'].append(Count)\n",
        "        clm['transaction_amount'].append(Amount)\n",
        "        clm ['state'].append(i)\n",
        "        clm ['year'].append(j)\n",
        "        clm ['quater'].append(int(k.strip('.json')))\n",
        "\n",
        "aggr_trans = pd.DataFrame(clm)\n",
        "# print(aggr_trans)\n"
      ],
      "metadata": {
        "id": "18x66YG046KN",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Aggregated User**"
      ],
      "metadata": {
        "id": "rA2rdY7SgPLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "aggr_usr_path = \"/content/pulse/data/aggregated/user/country/india/state\"\n",
        "\n",
        "Aggr_user_state_list = os.listdir(aggr_usr_path)\n",
        "print(Aggr_user_state_list)"
      ],
      "metadata": {
        "id": "FB58Dl8Ar-kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the Aggr_User\n",
        "\n",
        "clm = {'state':[], 'year':[], 'quater':[], 'User_Brand':[], 'User_count':[], 'User_percentage':[]}\n",
        "\n",
        "# Define the path to the aggregated user data\n",
        "agg_usr_path = \"/content/pulse/data/aggregated/user/country/india/state\"\n",
        "#print(os.listdir(agg_usr_path))\n",
        "\n",
        "# List all states (folders) in the given path\n",
        "Aggr_user_state_list = os.listdir(agg_usr_path)\n",
        "\n",
        "# pull data\n",
        "for i in Aggr_user_state_list:\n",
        "  p_i = os.path.join(agg_usr_path, i)\n",
        "  Aggr_yr = os.listdir(p_i)\n",
        "  #print(Aggr_yr)\n",
        "\n",
        "  for j in Aggr_yr:\n",
        "    p_j = os.path.join(p_i, j)\n",
        "    Aggr_qutr = os.listdir(p_j)\n",
        "    #print(Aggr_qutr)\n",
        "\n",
        "    #The for loop for to be indented to be in the j loop\n",
        "    for k in Aggr_qutr:\n",
        "      p_k = os.path.join(p_j, k)\n",
        "      #print('p_k')\n",
        "\n",
        "    # Open and load JSON data\n",
        "    with open(p_k, 'r') as Data:\n",
        "      D = json.load(Data)\n",
        "\n",
        "    # Check if 'usersByDevice' key exists and is not None\n",
        "    if D['data'] and 'usersByDevice' in D['data'] and D['data']['usersByDevice']:\n",
        "        for z in D['data']['usersByDevice']:\n",
        "            clm['User_Brand'].append(z['brand'])\n",
        "            clm['User_count'].append(z['count'])\n",
        "            clm['User_percentage'].append(z['percentage'])\n",
        "            clm['state'].append(i)\n",
        "            clm['year'].append(j)\n",
        "            clm['quater'].append(int(k.strip('.json')))\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "aggr_user = pd.DataFrame(clm)\n",
        "# print(aggr_user)\n"
      ],
      "metadata": {
        "id": "Mzl9rlhkNwvQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Aggregated insurance"
      ],
      "metadata": {
        "id": "YUYuwNPsHzh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the Aggregated_Insurance\n",
        "\n",
        "clm = {'state':[], 'year':[], 'quater':[], 'name':[], 'count':[], 'amount':[]}\n",
        "\n",
        "# Define the path to the aggregated insurance data\n",
        "aggr_insurance_path = \"/content/pulse/data/aggregated/insurance/country/india/state\"\n",
        "#print(os.listdir(aggr_insurance_path))\n",
        "\n",
        "\n",
        "# List all states (folders) in the given path\n",
        "Aggr_insurance_state_list = os.listdir(aggr_insurance_path)\n",
        "#print(Aggr_insurance_state_list)\n",
        "\n",
        "\n",
        "# pull data\n",
        "for i in Aggr_insurance_state_list:\n",
        "  p_i = os.path.join(aggr_insurance_path, i)\n",
        "  Aggr_yr = os.listdir(p_i)\n",
        "  #print(Aggr_yr)\n",
        "\n",
        "\n",
        "  for j in Aggr_yr:\n",
        "    p_j = os.path.join(p_i, j)\n",
        "    Aggr_qutr = os.listdir(p_j)\n",
        "    #print(Aggr_qutr)\n",
        "\n",
        "    #The for loop for to be indented to be in the j loop\n",
        "    for k in Aggr_qutr:\n",
        "      p_k = os.path.join(p_j, k)\n",
        "      #print(p_k)\n",
        "\n",
        "\n",
        "    # Open and load JSON data\n",
        "    with open(p_k, 'r') as Data:\n",
        "      D = json.load(Data)\n",
        "\n",
        "    # Loading data to clm\n",
        "    if D['data'] and 'transactionData' in D['data'] and D['data']['transactionData']:\n",
        "        for z in D['data']['transactionData']:\n",
        "            clm['name'].append(z['name'])\n",
        "            clm['count'].append(z['paymentInstruments'][0]['count'])\n",
        "            clm['amount'].append(z['paymentInstruments'][0]['amount'])\n",
        "            clm['state'].append(i)\n",
        "            clm['year'].append(j)\n",
        "            clm['quater'].append(int(k.strip('.json')))\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "aggr_insurance = pd.DataFrame(clm)\n",
        "#print(aggr_insurance)\n"
      ],
      "metadata": {
        "id": "cILrffhdILoa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Map insurance**"
      ],
      "metadata": {
        "id": "uE5pYwLqPqZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the Map_Insurance\n",
        "\n",
        "clm = {'state':[], 'year':[], 'quater':[], 'name':[], 'count':[], 'amount':[]}\n",
        "\n",
        "# Define the path to the map insurance data\n",
        "map_insurance_path = \"/content/pulse/data/map/insurance/country/india/state\"\n",
        "#print(os.listdir(map_insurance_path))\n",
        "\n",
        "\n",
        "# List all states (folders) in the given path\n",
        "map_insurance_state_list = os.listdir(map_insurance_path)\n",
        "#print(map_insurance_state_list)\n",
        "\n",
        "# pull data\n",
        "for i in Aggr_insurance_state_list:\n",
        "  p_i = os.path.join(aggr_insurance_path, i)\n",
        "  Aggr_yr = os.listdir(p_i)\n",
        "  #print(Aggr_yr)\n",
        "\n",
        "  for j in Aggr_yr:\n",
        "    p_j = os.path.join(p_i, j)\n",
        "    Aggr_qutr = os.listdir(p_j)\n",
        "    #print(Aggr_qutr)\n",
        "\n",
        "    #The for loop for to be indented to be in the j loop\n",
        "    for k in Aggr_qutr:\n",
        "      p_k = os.path.join(p_j, k)\n",
        "     #print(p_k)\n",
        "\n",
        "\n",
        "    # Open and load JSON data\n",
        "    with open(p_k, 'r') as Data:\n",
        "      D = json.load(Data)\n",
        "\n",
        "    # l;oading data to clm\n",
        "    if D['data'] and 'transactionData' in D['data'] and D['data']['transactionData']:\n",
        "        for z in D['data']['transactionData']:\n",
        "            clm['name'].append(z['name'])\n",
        "            clm['count'].append(z['paymentInstruments'][0]['count'])\n",
        "            clm['amount'].append(z['paymentInstruments'][0]['amount'])\n",
        "            clm['state'].append(i)\n",
        "            clm['year'].append(j)\n",
        "            clm['quater'].append(int(k.strip('.json')))\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "map_insurance = pd.DataFrame(clm)\n",
        "#print(map_insurance)\n"
      ],
      "metadata": {
        "id": "JVGvvXiKT27J",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Map user"
      ],
      "metadata": {
        "id": "RyKjV_J68bW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dictionary to store extracted data\n",
        "clm_user = {'state': [], 'year': [], 'quarter': [], 'district': [], 'registered_users': [], 'app_opens': []}\n",
        "\n",
        "# Set the file path\n",
        "map_user_path = \"/content/pulse/data/map/user/hover/country/india/state\"\n",
        "state_list = os.listdir(map_user_path)\n",
        "\n",
        "for state in state_list:\n",
        "    state_path = os.path.join(map_user_path, state)\n",
        "    if not os.path.isdir(state_path):  # Skip if not a directory\n",
        "        continue\n",
        "\n",
        "    year_list = os.listdir(state_path)\n",
        "\n",
        "    for year in year_list:\n",
        "        year_path = os.path.join(state_path, year)\n",
        "        if not os.path.isdir(year_path):  # Skip if not a directory\n",
        "            continue\n",
        "\n",
        "        quarter_list = os.listdir(year_path)\n",
        "\n",
        "        for quarter in quarter_list:\n",
        "            quarter_path = os.path.join(year_path, quarter)\n",
        "            if not quarter_path.endswith('.json'):  # Ensure it's a JSON file\n",
        "                continue\n",
        "\n",
        "            with open(quarter_path, 'r') as data_file:\n",
        "                data = json.load(data_file)\n",
        "\n",
        "            if data.get(\"data\") and \"hoverData\" in data[\"data\"]:\n",
        "                for district, values in data[\"data\"][\"hoverData\"].items():\n",
        "                    clm_user['state'].append(state)\n",
        "                    clm_user['year'].append(year)\n",
        "                    clm_user['quarter'].append(int(quarter.strip('.json')))\n",
        "                    clm_user['district'].append(district)\n",
        "                    clm_user['registered_users'].append(values.get('registeredUsers', 0))\n",
        "                    clm_user['app_opens'].append(values.get('appOpens', 0))\n",
        "\n",
        "# Convert to DataFrame\n",
        "map_user = pd.DataFrame(clm_user)\n",
        "#print(map_user)"
      ],
      "metadata": {
        "id": "qPC1FNnB8BJm",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Map transaction"
      ],
      "metadata": {
        "id": "c-hbfIMQ75tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clm_transaction = {'state': [], 'year': [], 'quater': [], 'transaction_count': [], 'transaction_amount': []}\n",
        "\n",
        "map_transaction_path = \"/content/pulse/data/map/transaction/hover/country/india\"\n",
        "year_list = os.listdir(map_transaction_path)\n",
        "\n",
        "for year in year_list:\n",
        "    year_path = os.path.join(map_transaction_path, year)\n",
        "\n",
        "    if not os.path.isdir(year_path):  # Skip if it's not a directory\n",
        "        continue\n",
        "\n",
        "    quarter_list = os.listdir(year_path)\n",
        "\n",
        "    for quarter in quarter_list:\n",
        "        quarter_path = os.path.join(year_path, quarter)\n",
        "\n",
        "        if not quarter_path.endswith('.json'):  # Skip non-JSON files\n",
        "            continue\n",
        "\n",
        "        with open(quarter_path, 'r') as Data:\n",
        "            D = json.load(Data)\n",
        "\n",
        "        if 'data' in D and 'hoverDataList' in D['data']:\n",
        "            for entry in D['data']['hoverDataList']:\n",
        "                clm_transaction['state'].append(entry['name'])\n",
        "                clm_transaction['year'].append(year)\n",
        "                clm_transaction['quater'].append(int(quarter.strip('.json')))\n",
        "                clm_transaction['transaction_count'].append(entry['metric'][0]['count'])\n",
        "                clm_transaction['transaction_amount'].append(entry['metric'][0]['amount'])\n",
        "\n",
        "map_transaction = pd.DataFrame(clm_transaction)\n",
        "#print(map_transaction)"
      ],
      "metadata": {
        "id": "70yh1-Ds7wiW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Top insurance"
      ],
      "metadata": {
        "id": "4bQf1d8X9aa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data structure\n",
        "clm_insurance = {'state':[], 'year':[], 'quater':[], 'district/pincode':[], 'top_insurance_count':[], 'top_insurance_amount':[]}\n",
        "\n",
        "# Define the path to the top insurance data\n",
        "top_insurance_path = \"/content/pulse/data/top/insurance/country/india/state\"\n",
        "Top_insurance_state_list = os.listdir(top_insurance_path)\n",
        "\n",
        "# Extract data\n",
        "for i in Top_insurance_state_list:\n",
        "    p_i = os.path.join(top_insurance_path, i)\n",
        "    Top_yr = os.listdir(p_i)\n",
        "\n",
        "    for j in Top_yr:\n",
        "        p_j = os.path.join(p_i, j)\n",
        "        Top_qutr = os.listdir(p_j)\n",
        "\n",
        "        for k in Top_qutr:\n",
        "            p_k = os.path.join(p_j, k)\n",
        "\n",
        "            with open(p_k, 'r') as Data:\n",
        "                D = json.load(Data)\n",
        "\n",
        "            if D['data']:\n",
        "                # Extract district data\n",
        "                if 'districts' in D['data'] and D['data']['districts']:\n",
        "                    for dist in D['data']['districts']:\n",
        "                        clm_insurance['state'].append(i)\n",
        "                        clm_insurance['year'].append(j)\n",
        "                        clm_insurance['quater'].append(int(k.strip('.json')))\n",
        "                        clm_insurance['district/pincode'].append(dist['entityName'])\n",
        "                        clm_insurance['top_insurance_count'].append(dist['metric']['count'])\n",
        "                        clm_insurance['top_insurance_amount'].append(dist['metric']['amount'])\n",
        "\n",
        "                # Extract pincode data\n",
        "                if 'pincodes' in D['data'] and D['data']['pincodes']:\n",
        "                    for pin in D['data']['pincodes']:\n",
        "                        clm_insurance['state'].append(i)\n",
        "                        clm_insurance['year'].append(j)\n",
        "                        clm_insurance['quater'].append(int(k.strip('.json')))\n",
        "                        clm_insurance['district/pincode'].append(pin['entityName'])\n",
        "                        clm_insurance['top_insurance_count'].append(pin['metric']['count'])\n",
        "                        clm_insurance['top_insurance_amount'].append(pin['metric']['amount'])\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "top_insurance = pd.DataFrame(clm_insurance)\n",
        "#print(top_insurance)"
      ],
      "metadata": {
        "id": "9WHLkRJz9Wm7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Top transactions"
      ],
      "metadata": {
        "id": "4kSp5ZUP-nIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data structure\n",
        "clm = {'state':[], 'year':[], 'quater':[], 'district/pincode':[], 'top_transaction_count':[], 'top_transaction_amount':[]}\n",
        "\n",
        "# Define the path to the top transactions data\n",
        "top_txn_path = \"/content/pulse/data/top/transaction/country/india/state\"\n",
        "Top_txn_state_list = os.listdir(top_txn_path)\n",
        "\n",
        "# Extract data\n",
        "for i in Top_txn_state_list:\n",
        "    p_i = os.path.join(top_txn_path, i)\n",
        "    Top_yr = os.listdir(p_i)\n",
        "\n",
        "    for j in Top_yr:\n",
        "        p_j = os.path.join(p_i, j)\n",
        "        Top_qutr = os.listdir(p_j)\n",
        "\n",
        "        for k in Top_qutr:\n",
        "            p_k = os.path.join(p_j, k)\n",
        "\n",
        "            with open(p_k, 'r') as Data:\n",
        "                D = json.load(Data)\n",
        "\n",
        "            if D['data']:\n",
        "                # Extract district data\n",
        "                if 'districts' in D['data'] and D['data']['districts']:\n",
        "                    for dist in D['data']['districts']:\n",
        "                        clm['state'].append(i)\n",
        "                        clm['year'].append(j)\n",
        "                        clm['quater'].append(int(k.strip('.json')))\n",
        "                        clm['district/pincode'].append(dist['entityName'])\n",
        "                        clm['top_transaction_count'].append(dist['metric']['count'])\n",
        "                        clm['top_transaction_amount'].append(dist['metric']['amount'])\n",
        "\n",
        "                # Extract pincode data\n",
        "                if 'pincodes' in D['data'] and D['data']['pincodes']:\n",
        "                    for pin in D['data']['pincodes']:\n",
        "                        clm['state'].append(i)\n",
        "                        clm['year'].append(j)\n",
        "                        clm['quater'].append(int(k.strip('.json')))\n",
        "                        clm['district/pincode'].append(pin['entityName'])\n",
        "                        clm['top_transaction_count'].append(pin['metric']['count'])\n",
        "                        clm['top_transaction_amount'].append(pin['metric']['amount'])\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "top_transaction = pd.DataFrame(clm)\n",
        "#print(top_transaction)"
      ],
      "metadata": {
        "id": "KHoO_R-G-nl5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Top user"
      ],
      "metadata": {
        "id": "OcLUylBL7rAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dictionary structure\n",
        "clm_user = {'state': [], 'year': [], 'quater': [], 'district/pincode': [], 'top_user_count': []}\n",
        "\n",
        "# Define the path\n",
        "top_user_path = \"/content/pulse/data/top/user/country/india/state\"\n",
        "Top_user_state_list = os.listdir(top_user_path)\n",
        "\n",
        "for i in Top_user_state_list:\n",
        "    p_i = os.path.join(top_user_path, i)\n",
        "    Top_yr = os.listdir(p_i)\n",
        "\n",
        "    for j in Top_yr:\n",
        "        p_j = os.path.join(p_i, j)\n",
        "        Top_qutr = os.listdir(p_j)\n",
        "\n",
        "        for k in Top_qutr:\n",
        "            p_k = os.path.join(p_j, k)\n",
        "\n",
        "            with open(p_k, 'r') as Data:\n",
        "                D = json.load(Data)\n",
        "\n",
        "            if D['data']:\n",
        "                # Extract district data\n",
        "                if 'districts' in D['data'] and D['data']['districts']:\n",
        "                    for dist in D['data']['districts']:\n",
        "                        clm_user['state'].append(i)\n",
        "                        clm_user['year'].append(j)\n",
        "                        clm_user['quater'].append(int(k.strip('.json')))\n",
        "                        clm_user['district/pincode'].append(dist['name'])\n",
        "                        clm_user['top_user_count'].append(dist['registeredUsers'])\n",
        "\n",
        "                # Extract pincode data\n",
        "                if 'pincodes' in D['data'] and D['data']['pincodes']:\n",
        "                    for pin in D['data']['pincodes']:\n",
        "                        clm_user['state'].append(i)\n",
        "                        clm_user['year'].append(j)\n",
        "                        clm_user['quater'].append(int(k.strip('.json')))\n",
        "                        clm_user['district/pincode'].append(pin['name'])\n",
        "                        clm_user['top_user_count'].append(pin['registeredUsers'])\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "top_user = pd.DataFrame(clm_user)\n",
        "#print(top_user)"
      ],
      "metadata": {
        "id": "2FTWcmt-Yf4f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Store the extracted data into sql server"
      ],
      "metadata": {
        "id": "ezWVmdOgQfOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install & Import the necessary libraries"
      ],
      "metadata": {
        "id": "VDjcCzo5QYRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sqlalchemy pymysql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7UN-VUQPzBM",
        "outputId": "919dc113-9e09-412c-ca13-1868f769ed78"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.40)\n",
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.13.1)\n",
            "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine"
      ],
      "metadata": {
        "id": "7c93V9CdPy-r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## connection to SQL"
      ],
      "metadata": {
        "id": "KUeol1vMQQSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Connection details\n",
        "username = userdata.get(\"Sql_username\")\n",
        "password = userdata.get(\"Sql_password\")\n",
        "host = userdata.get(\"Sql_host\")\n",
        "port = 3306\n",
        "database = userdata.get(\"Sql_database\")"
      ],
      "metadata": {
        "id": "UpnyVSGERVae"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create engine for MySQL\n",
        "engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}:{port}/{database}\")"
      ],
      "metadata": {
        "id": "q73NjwlpPy7x"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store the DataFrame into SQL table"
      ],
      "metadata": {
        "id": "xJp2YwfTU2Z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store each DataFrame into its respective SQL table\n",
        "aggr_trans.to_sql('aggr_trans_data', con=engine, if_exists='replace', index=False)\n",
        "aggr_user.to_sql('aggr_user_data', con=engine, if_exists='replace', index=False)\n",
        "aggr_insurance.to_sql('aggr_insurance_data', con=engine, if_exists='replace', index=False)\n",
        "map_insurance.to_sql('map_insurance_data', con=engine, if_exists='replace', index=False)\n",
        "map_user.to_sql('map_user_data', con=engine, if_exists='replace', index=False)\n",
        "map_transaction.to_sql('map_transaction_data', con=engine, if_exists='replace', index=False)\n",
        "top_insurance.to_sql('top_insurance_data', con=engine, if_exists='replace', index=False)\n",
        "top_transaction.to_sql('top_transaction_data', con=engine, if_exists='replace', index=False)\n",
        "top_user.to_sql('top_transaction_data', con=engine, if_exists='replace', index=False)\n",
        "\n",
        "print(\"✅ All data inserted successfully into the MySQL database.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNMsZI0DPy5I",
        "outputId": "f54a35d3-b658-4d82-e8e8-a27321322d3d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All data inserted successfully into the MySQL database.\n"
          ]
        }
      ]
    }
  ]
}